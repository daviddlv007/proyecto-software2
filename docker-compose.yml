# ============================================
# DOCKER COMPOSE - Proyecto SW2
# DESARROLLO: SQLite (ultra liviano, <1GB RAM)
# PRODUCCIÓN: PostgreSQL (usar docker-compose.prod.yml)
# ============================================

networks:
  app-network:
    driver: bridge

volumes:
  # SQLite files persistentes
  pgdata:
  core-db-data:
  ml-db-data:
  dl-db-data:
  ml-models:
  dl-models:
  dl-uploads:

services:

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: coredb
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5433:5432"  # si ya tienes un Postgres local, usa "5433:5432"
    networks:
      - app-network
    volumes:
      - pgdata:/var/lib/postgresql/data
      # (opcional) Semillas iniciales en el primer arranque:
      # - ./db/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d coredb"]
      interval: 10s
      timeout: 3s
      retries: 10
  # ==========================================
  # CORE SERVICE - Spring Boot + GraphQL
  # ==========================================
  core-service:
    build:
      context: ./core-service
      dockerfile: Dockerfile
    container_name: core-service
    restart: unless-stopped
    environment:
     #para obetenet el webhook en el servidor 
#stripe login
#stripe listen --forward-to http://localhost:8080/webhooks/stripe
      # --- Features ---
      FEATURE_DELIVERY: "true"          #activar para usar 
      FEATURE_PAYMENTS: "true"
      FEATURE_VOICE_AI: "true"

      # --- Google Maps ---
      GOOGLE_MAPS_API_KEY: ${GOOGLE_MAPS_API_KEY}

    # JWT (opcional en desarrollo)
      JWT_SECRET: ${JWT_SECRET:-mi-secreto-jwt-desarrollo}
      
      # Delivery (coordenadas de tu tienda)
      DELIVERY_ORIGIN_LAT: ${DELIVERY_ORIGIN_LAT:--17.7833}
      DELIVERY_ORIGIN_LNG: ${DELIVERY_ORIGIN_LNG:--63.1821}
      DELIVERY_BASE_FEE: ${DELIVERY_BASE_FEE:-1.5}
      DELIVERY_PER_KM: ${DELIVERY_PER_KM:-0.6}
      # --- Stripe (si ya estás probando pagos) ---
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET}
      APP_SUCCESS_URL: ${APP_SUCCESS_URL:-http://localhost:5173/pago-exitoso}
      APP_CANCEL_URL: ${APP_CANCEL_URL:-http://localhost:5173/pago-cancelado}
      CURRENCY: ${CURRENCY:-USD}

      # --- OpenAI (voz/IA) ---
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_TRANSCRIBE_MODEL: ${OPENAI_TRANSCRIBE_MODEL:-whisper-1}
      OPENAI_TEXT_MODEL: ${OPENAI_TEXT_MODEL:-gpt-4o-mini}


      SPRING_FLYWAY_ENABLED: "true"
      SPRING_FLYWAY_BASELINE_ON_MIGRATE: "true"
      SPRING_FLYWAY_SCHEMAS: public
      SPRING_FLYWAY_LOCATIONS: classpath:db/migration
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/coredb
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: postgres
      SPRING_DATASOURCE_DRIVER: org.postgresql.Driver
      SPRING_JPA_HIBERNATE_DDL_AUTO: update   # crea/actualiza tablas
      SERVER_PORT: 8080
      # (opcional) logs SQL:
      # LOGGING_LEVEL_org.hibernate.SQL: DEBUG
      # LOGGING_LEVEL_org.hibernate.type.descriptor.sql.BasicBinder: TRACE
    depends_on:
      postgres:
        condition: service_healthy
    # ya no necesitas el volumen de H2:
    # volumes:
    #   - core-db-data:/data
    networks:
      - app-network
    ports:
      - "${CORE_PORT:-8080}:8080"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==========================================
  # ML SERVICE - FastAPI + SQLite
  # ==========================================
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: ml-service
    restart: unless-stopped
    depends_on:
      core-service:
        condition: service_healthy
    environment:
      # SQLite file-based (sin container DB)
      DATABASE_URL: sqlite:////data/ml_cache.db
      CORE_SERVICE_URL: http://core-service:8080/graphql
      PORT: 8081
      WORKERS: 1
      PYTHONUNBUFFERED: "1"
    volumes:
      - ml-db-data:/data
      - ml-models:/app/models
      # Hot reload: montar código fuente
      - ./ml-service/app:/app/app:ro
    networks:
      - app-network
    ports:
      - "${ML_PORT:-8081}:8081"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 384M
        reservations:
          memory: 128M
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8081/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # ==========================================
  # DL SERVICE - Node.js + TensorFlow.js + SQLite
  # ==========================================
  dl-service:
    build:
      context: ./dl-service
      dockerfile: Dockerfile.dev
    container_name: dl-service
    restart: unless-stopped
    depends_on:
      core-service:
        condition: service_healthy
    environment:
      # Sin DB en desarrollo (cache en memoria)
      DATABASE_URL: ""
      CORE_SERVICE_URL: http://core-service:8080/graphql
      PORT: 8082
      NODE_ENV: development
      # Memory optimizado
      NODE_OPTIONS: "--max-old-space-size=384"
    volumes:
      - dl-db-data:/data
      - dl-models:/app/models
      - dl-uploads:/app/uploads
      # Hot reload: montar código fuente
      - ./dl-service/src:/app/src:ro
      - ./dl-service/package.json:/app/package.json:ro
    networks:
      - app-network
    ports:
      - "${DL_PORT:-8082}:8082"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 192M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8082/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s

  # ==========================================
  # FRONTEND - Vite Dev Server (Hot Reload) 
  # Moderno y minimalista - 2025
  # ==========================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: frontend
    restart: unless-stopped
    depends_on:
      - core-service
      - ml-service
      - dl-service
    environment:
      VITE_CORE_API_URL: ${CORE_API_URL:-http://localhost:8080/graphql}
      VITE_ML_API_URL: ${ML_API_URL:-http://localhost:8081}
      VITE_DL_API_URL: ${DL_API_URL:-http://localhost:8082}
    volumes:
      # Hot reload: montar código fuente
      - ./frontend/src:/app/src:ro
      - ./frontend/public:/app/public:ro
      - ./frontend/index.html:/app/index.html:ro
      - ./frontend/vite.config.ts:/app/vite.config.ts:ro
      # node_modules como volumen para performance
      - /app/node_modules
    networks:
      - app-network
    ports:
      - "${FRONTEND_PORT:-5173}:5173"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          memory: 192M
    healthcheck:
      # Usar wget que es más confiable que nc en BusyBox Alpine
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "--timeout=3", "http://localhost:5173/"]
      interval: 30s
      timeout: 5s
      retries: 3
      # El servidor de desarrollo puede tardar en arrancar; subir start_period
      start_period: 30s

  # ==========================================
  # BI SERVICE - Django + PostgreSQL + Gemini AI
  # Business Intelligence Dashboard
  # ==========================================
  bi-service:
    build:
      context: ./bi-service
      dockerfile: Dockerfile
    container_name: bi-service
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      core-service:
        condition: service_started
    environment:
      # Django settings
      DJANGO_SECRET_KEY: ${DJANGO_SECRET_KEY:-django-insecure-development-key}
      DEBUG: ${DEBUG:-True}
      ALLOWED_HOSTS: ${ALLOWED_HOSTS:-*}
      
      # BI Database (propia del servicio BI)
      BI_DB_NAME: ${BI_DB_NAME:-software2_DB}
      BI_DB_USER: ${BI_DB_USER:-postgres}
      BI_DB_PASSWORD: ${BI_DB_PASSWORD:-postgres}
      BI_DB_HOST: postgres
      BI_DB_PORT: 5432
      
      # Core Database (lectura para análisis BI)
      CORE_DB_NAME: ${POSTGRES_DB:-coredb}
      CORE_DB_USER: ${POSTGRES_USER:-postgres}
      CORE_DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      CORE_DB_HOST: postgres
      CORE_DB_PORT: 5432
      
      # Gemini AI
      GEMINI_API_KEY: ${GEMINI_API_KEY}
      
      # Email (opcional)
      EMAIL_HOST_USER: ${EMAIL_HOST_USER:-}
      EMAIL_HOST_PASSWORD: ${EMAIL_HOST_PASSWORD:-}
      
      # Fernet encryption
      FERNET_KEY: ${FERNET_KEY:-7JCjohc5fLJclS0PM4dE98mJne239a7yF8N0WUR7uxI=}
    networks:
      - app-network
    ports:
      - "${BI_PORT:-8083}:8083"
    volumes:
      # Hot reload para desarrollo
      - ./bi-service:/app
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 768M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8083', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
